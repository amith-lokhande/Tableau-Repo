{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25948ee3-12f2-42f7-8ed2-3c5ad8a84afb",
   "metadata": {},
   "source": [
    "<H1><center> Covid-19 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae706845-3eea-4ba7-b10f-eff4609e407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75871bfd-2291-4cdf-ab07-77d5c05e2717",
   "metadata": {},
   "source": [
    "## 1st CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce00127e-06c6-4545-afea-7e5e47f390e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-01-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23-01-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24-01-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-01-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26-01-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Country  Confirmed  Recovered  Deaths\n",
       "0  22-01-20  Afghanistan          0          0       0\n",
       "1  23-01-20  Afghanistan          0          0       0\n",
       "2  24-01-20  Afghanistan          0          0       0\n",
       "3  25-01-20  Afghanistan          0          0       0\n",
       "4  26-01-20  Afghanistan          0          0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = '1. countries-aggregated.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Now you have the data in a DataFrame, and you can perform various operations on it\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc23470-b67c-4744-90f1-48e6ccaeb688",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04175706-3dd7-45e1-9fd4-75086a715013",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ef3962-277b-4ca3-a35f-2161353e5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shape of the column is: (161568, 5) \n",
      "\n",
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date         object\n",
      "Country      object\n",
      "Confirmed     int64\n",
      "Recovered     int64\n",
      "Deaths        int64\n",
      "dtype: object \n",
      "\n",
      "Checking for missing values in the df:\n",
      "\n",
      " Date         0\n",
      "Country      0\n",
      "Confirmed    0\n",
      "Recovered    0\n",
      "Deaths       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inital details of the dataset\n",
    "\n",
    "# Checking the total number of rows and columns in the df\n",
    "print(\"The initial shape of the column is:\",df.shape,\"\\n\")\n",
    "\n",
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df.dtypes,\"\\n\")\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Checking for missing values in the df:\\n\\n\",df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da7345-7578-45be-b256-204f0f26baae",
   "metadata": {},
   "source": [
    "***There are no Null values in the data so we proceed further!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f8fd1-53c0-445c-93a8-fdf40cd77b9a",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c5887-7cee-4bff-800a-dac018f2cba3",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badeb1a1-9355-4eb9-9b79-e6cb8a430c46",
   "metadata": {},
   "source": [
    "#### a. Confirmed Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3eb7e2-482c-48ff-b9ee-2e973c2a9b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "confirmed_per_day = np.zeros(len(df))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country = df['Country'].values\n",
    "confirmed = df['Confirmed'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Confirmed per day\"\n",
    "for i in range(1, len(df)):\n",
    "    if country[i] == country[i-1]:  # Compare the current country with the previous country\n",
    "        confirmed_per_day[i] = confirmed[i] - confirmed[i-1]  # Confirmed for current day - Confirmed for previous day\n",
    "    else:\n",
    "        confirmed_per_day[i] = confirmed[i]  # Confirmed for current day\n",
    "\n",
    "# Assign the calculated values to the 'Confirmed per day' column in the DataFrame\n",
    "df['Confirmed per day'] = confirmed_per_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671635d4-6403-420b-9978-69d8ee883e48",
   "metadata": {},
   "source": [
    "![Countries Data](https://i.imgur.com/jwPBTVn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff50f4f-5c5f-41ff-a363-00e5956180b5",
   "metadata": {},
   "source": [
    "#### b. Recovered Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a95fa4-a7b9-44f7-958d-354c87f6c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "recovered_extended = np.zeros(len(df))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country = df['Country'].values\n",
    "recovered = df['Recovered'].values\n",
    "\n",
    "# Use a for loop to iterate over the rows of the DataFrame\n",
    "for i in range(1, len(df)):\n",
    "    # Check if the current row's 'Country/Region' and 'Province/State' values are equal to the previous row's values\n",
    "    if country[i] == country[i-1]:\n",
    "        # Check if the current row's 'Recovered' value is equal to 0\n",
    "        if recovered[i] == 0:\n",
    "            # Set the current row's 'Recovered Extended' value to the previous row's value\n",
    "            recovered_extended[i] = recovered_extended[i-1]\n",
    "        else:\n",
    "            # Set the current row's 'Recovered Extended' value to the maximum value between the current and previous rows' 'Recovered' values\n",
    "            recovered_extended[i] = np.maximum(recovered[i], recovered[i-1])\n",
    "\n",
    "# Assign the calculated values to the 'Recovered Extended' column in the DataFrame\n",
    "df['Recovered Extended'] = recovered_extended\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "recovered_per_day = np.zeros(len(df))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country = df['Country'].values\n",
    "recovered_extended = df['Recovered Extended'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Recovered per day\"\n",
    "for i in range(1, len(df)):\n",
    "    if country[i] == country[i-1]:  # Compare the current country with the previous country\n",
    "        recovered_per_day[i] = recovered_extended[i] - recovered_extended[i-1]  # Recovered for current day - Recovered for previous day\n",
    "    else:\n",
    "        recovered_per_day[i] = recovered_extended[i]  # Recovered for current day\n",
    "\n",
    "# Assign the calculated values to the 'Recovered per day' column in the DataFrame\n",
    "df['Recovered per day'] = recovered_per_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393329a1-15fd-486e-a22b-85a1354f831e",
   "metadata": {},
   "source": [
    "#### c. Deaths Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723bb717-7a3c-4cc8-8baa-4247e612d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "deaths_per_day = np.zeros(len(df))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country = df['Country'].values\n",
    "deaths = df['Deaths'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Deaths per day\"\n",
    "for i in range(1, len(df)):\n",
    "    if country[i] == country[i-1]:  # Compare the current country with the previous country\n",
    "        deaths_per_day[i] = deaths[i] - deaths[i-1]  # Deaths for current day - Deaths for previous day\n",
    "    else:\n",
    "        deaths_per_day[i] = deaths[i]  # Deaths for current day\n",
    "\n",
    "# Assign the calculated values to the 'Deaths per day' column in the DataFrame\n",
    "df['Deaths per day'] = deaths_per_day\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Reassign the DataFrame with the desired order of columns\n",
    "df = df[['Date', 'Country', 'Confirmed', 'Confirmed per day', 'Recovered', 'Recovered Extended', 'Recovered per day', 'Deaths', 'Deaths per day']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac3ac5-f393-4c6f-b141-a1c6952a1347",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85485327-6277-4721-9d03-06b6e722ac91",
   "metadata": {},
   "source": [
    "### Confirming Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beee71fb-4b8c-496f-8c8e-2e9ca5ca91a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Confirmed per day                  : 504155459.0\n",
      "Max(Sum(Confirmed Extended)) per Country  : 504155459\n",
      "\n",
      "Sum of Recovered per day                  : 137243837.0\n",
      "Max(Sum(Recovered Extended)) per Country  : 137243837.0\n",
      "\n",
      "Sum of Deaths per day                     : 6197159.0\n",
      "Max(Sum(Deaths Extended)) per Country     : 6197159\n"
     ]
    }
   ],
   "source": [
    "# Converting Date fields for accurate calculations\n",
    "\n",
    "# Convert the \"Date\" column to pandas datetime using the specified format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%y')\n",
    "# Specify the target date in datetime format\n",
    "target_date = pd.to_datetime('16-04-2022', format='%d-%m-%Y')  # \"Y\" stands for 4 digits in Years where as \"y\" stands for 2 digits\n",
    "# Filter the DataFrame to include only rows with the target date\n",
    "target_rows = df[df['Date'] == target_date]\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Calculate the sum of \"Confirmed Extended\", \"Recovered Extended\", and \"Deaths Extended\" for the filtered rows\n",
    "sum_confirmed_on_target_date = target_rows['Confirmed'].sum()\n",
    "sum_rec_ext_on_target_date = target_rows['Recovered Extended'].sum()\n",
    "sum_deaths_on_target_date = target_rows['Deaths'].sum()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Get the sum of the values in the \"Confirmed per day\", \"Recovered per day\", and \"Deaths per day\" columns\n",
    "sum_confirmed_per_day = df['Confirmed per day'].sum()\n",
    "sum_recovered_per_day = df['Recovered per day'].sum()\n",
    "sum_deaths_per_day = df['Deaths per day'].sum()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Printing the relevant values\n",
    "print(\"Sum of Confirmed per day                  :\", sum_confirmed_per_day)\n",
    "print(f\"Max(Sum(Confirmed Extended)) per Country  : {sum_confirmed_on_target_date}\\n\")\n",
    "print(\"Sum of Recovered per day                  :\", sum_recovered_per_day)\n",
    "print(f\"Max(Sum(Recovered Extended)) per Country  : {sum_rec_ext_on_target_date}\\n\")\n",
    "print(\"Sum of Deaths per day                     :\", sum_deaths_per_day)\n",
    "print(f\"Max(Sum(Deaths Extended)) per Country     : {sum_deaths_on_target_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0478ba-7556-4659-a73c-5bd65ff11b9c",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9517ad3-db94-40eb-ab77-95d931754a66",
   "metadata": {},
   "source": [
    "### Data Cleaning Post Transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c09610a5-8c4d-44b7-810a-7945e3abe26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date                  datetime64[ns]\n",
      "Country                       object\n",
      "Confirmed                      int64\n",
      "Confirmed per day            float64\n",
      "Recovered                      int64\n",
      "Recovered Extended           float64\n",
      "Recovered per day            float64\n",
      "Deaths                         int64\n",
      "Deaths per day               float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df.dtypes,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba6c25b-4320-4e54-8fd2-33ee84078a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the \"datetime64\" datatype from \"Date\" column\n",
    "df['Date'] = df['Date'].dt.date\n",
    "\n",
    "\n",
    "# Converting all the \"float64\" datatypes to \"int64\"\n",
    "cols = [ 'Confirmed per day', 'Recovered Extended', 'Recovered per day', 'Deaths per day']\n",
    "df[cols] = df[cols].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9caac02e-8756-482c-aa15-f2fff1f5f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date                  object\n",
      "Country               object\n",
      "Confirmed              int64\n",
      "Confirmed per day      int64\n",
      "Recovered              int64\n",
      "Recovered Extended     int64\n",
      "Recovered per day      int64\n",
      "Deaths                 int64\n",
      "Deaths per day         int64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df.dtypes,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06c607-3c9c-43f2-8ba0-3abb731550cb",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff65a0-98bc-416f-a8fc-e3b7708b539d",
   "metadata": {},
   "source": [
    "### Converting df into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8061a7b6-9543-47c9-8948-1fa9e52b3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired file name along with the file extension in the file path\n",
    "file_name = '1a. countries_transformed.csv'  # Replace 'your_file_name' with your desired name\n",
    "\n",
    "# Convert the DataFrame to an Excel file\n",
    "df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dead3b-2e50-4359-ba50-f20108bbd532",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4432a4-e351-4649-9edf-951dad1fa600",
   "metadata": {},
   "source": [
    "## 2nd CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8970d5-bba9-496c-aded-a42eefad3ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Country/Region Province/State  Confirmed  Recovered  Deaths\n",
      "0  2020-01-22    Afghanistan            NaN          0        0.0       0\n",
      "1  2020-01-23    Afghanistan            NaN          0        0.0       0\n",
      "2  2020-01-24    Afghanistan            NaN          0        0.0       0\n",
      "3  2020-01-25    Afghanistan            NaN          0        0.0       0\n",
      "4  2020-01-26    Afghanistan            NaN          0        0.0       0\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = '2. time-series-19-covid-combined.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df2 = pd.read_csv(file_path)\n",
    "\n",
    "# Now you have the data in a DataFrame, and you can perform various operations on it\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33ab41-ccfd-425f-9960-6aeeeed64a2d",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72929c0a-d33f-4adf-af32-8339db06868f",
   "metadata": {},
   "source": [
    "### Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8da3a863-b123-4d8b-be5b-2ba64510d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shape of the column is: (231744, 6) \n",
      "\n",
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date               object\n",
      "Country/Region     object\n",
      "Province/State     object\n",
      "Confirmed           int64\n",
      "Recovered         float64\n",
      "Deaths              int64\n",
      "dtype: object \n",
      "\n",
      "Checking for missing values in the df2:\n",
      "\n",
      " Date                   0\n",
      "Country/Region         0\n",
      "Province/State    159120\n",
      "Confirmed              0\n",
      "Recovered          13056\n",
      "Deaths                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inital details of the dataset\n",
    "\n",
    "# Checking the total number of rows and columns in the df2\n",
    "print(\"The initial shape of the column is:\",df2.shape,\"\\n\")\n",
    "\n",
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df2.dtypes,\"\\n\")\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Checking for missing values in the df2:\\n\\n\",df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edf3e5f5-b16a-48bd-9714-443ddf8a919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values in the df2:\n",
      "\n",
      " Date              0\n",
      "Country/Region    0\n",
      "Province/State    0\n",
      "Confirmed         0\n",
      "Recovered         0\n",
      "Deaths            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2['Province/State'].fillna('-', inplace=True)\n",
    "df2['Recovered'].fillna(0, inplace=True)\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Checking for missing values in the df2:\\n\\n\",df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe402234-ab10-40cd-bc33-348c68bbbab9",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1580a-b191-4639-b16a-2ccb6afb9bc6",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca193fd4-f9de-4bdf-9b87-9917c54f61d4",
   "metadata": {},
   "source": [
    "![Countries and States Data](https://i.imgur.com/EhG4aam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56090c4c-3427-473c-8759-0cd48f1fee93",
   "metadata": {},
   "source": [
    "#### a. Confirmed Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e6b3bbe-0667-43d0-98b7-6fbc6a7c02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 812 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "confirmed_extended = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "confirmed = df2['Confirmed'].values\n",
    "\n",
    "# Use a for loop to iterate over the rows of the DataFrame\n",
    "for i in range(1, len(df2)):\n",
    "    # Check if the current row's 'Country/Region' and 'Province/State' values are equal to the previous row's values\n",
    "    if country_region[i] == country_region[i-1] and province_state[i] == province_state[i-1]:\n",
    "        # Check if the current row's 'Confirmed' value is equal to 0\n",
    "        if confirmed[i] == 0:\n",
    "            # Set the current row's 'Confirmed Extended' value to the previous row's value\n",
    "            confirmed_extended[i] = confirmed_extended[i-1]\n",
    "        else:\n",
    "            # Set the current row's 'Confirmed Extended' value to the maximum value between the current and previous rows' 'Confirmed' values\n",
    "            confirmed_extended[i] = np.maximum(confirmed[i], confirmed[i-1])\n",
    "\n",
    "# Assign the calculated values to the 'Confirmed Extended' column in the DataFrame\n",
    "df2['Confirmed Extended'] = confirmed_extended\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "confirmed_per_day = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "confirmed_extended = df2['Confirmed Extended'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Confirmed per day\"\n",
    "for i in range(1, len(df2)):\n",
    "    current_country = country_region[i]\n",
    "    current_province = province_state[i]\n",
    "    prev_country = country_region[i - 1]\n",
    "    prev_province = province_state[i - 1]\n",
    "\n",
    "    if current_country == prev_country and (current_province == prev_province or (pd.isna(current_province) and pd.isna(prev_province))):\n",
    "        confirmed_per_day[i] = confirmed_extended[i] - confirmed_extended[i - 1]\n",
    "    else:\n",
    "        confirmed_per_day[i] = confirmed_extended[i]\n",
    "\n",
    "# Assign the calculated values to the 'Confirmed per day' column in the DataFrame\n",
    "df2['Confirmed per day'] = confirmed_per_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07c5d7-b418-4a4a-98bc-5cb8a7efe08c",
   "metadata": {},
   "source": [
    "#### b. Recovered Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cdf38e-fbe4-4221-8959-19c77621ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 875 ms\n",
      "Wall time: 873 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "recovered_extended = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "recovered = df2['Recovered'].values\n",
    "\n",
    "# Use a for loop to iterate over the rows of the DataFrame\n",
    "for i in range(1, len(df2)):\n",
    "    # Check if the current row's 'Country/Region' and 'Province/State' values are equal to the previous row's values\n",
    "    if country_region[i] == country_region[i-1] and province_state[i] == province_state[i-1]:\n",
    "        # Check if the current row's 'Recovered' value is equal to 0\n",
    "        if recovered[i] == 0:\n",
    "            # Set the current row's 'Recovered Extended' value to the previous row's value\n",
    "            recovered_extended[i] = recovered_extended[i-1]\n",
    "        else:\n",
    "            # Set the current row's 'Recovered Extended' value to the maximum value between the current and previous rows' 'Recovered' values\n",
    "            recovered_extended[i] = np.maximum(recovered[i], recovered[i-1])\n",
    "\n",
    "# Assign the calculated values to the 'Recovered Extended' column in the DataFrame\n",
    "df2['Recovered Extended'] = recovered_extended\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "recovered_per_day = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "recovered_extended = df2['Recovered Extended'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Recovered per day\"\n",
    "for i in range(1, len(df2)):\n",
    "    current_country = country_region[i]\n",
    "    current_province = province_state[i]\n",
    "    prev_country = country_region[i - 1]\n",
    "    prev_province = province_state[i - 1]\n",
    "\n",
    "    if current_country == prev_country and (current_province == prev_province or (pd.isna(current_province) and pd.isna(prev_province))):\n",
    "        recovered_per_day[i] = recovered_extended[i] - recovered_extended[i - 1]\n",
    "    else:\n",
    "        recovered_per_day[i] = recovered_extended[i]\n",
    "\n",
    "# Assign the calculated values to the 'Recovered per day' column in the DataFrame\n",
    "df2['Recovered per day'] = recovered_per_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dca936-46c2-4fa5-a812-8dbdbd68990d",
   "metadata": {},
   "source": [
    "#### c. Deaths Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ed5b59-50bb-44d3-93c4-33357edbb9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.86 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "deaths_extended = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "deaths = df2['Deaths'].values\n",
    "\n",
    "# Use a for loop to iterate over the rows of the DataFrame\n",
    "for i in range(1, len(df2)):\n",
    "    # Check if the current row's 'Country/Region' and 'Province/State' values are equal to the previous row's values\n",
    "    if country_region[i] == country_region[i-1] and province_state[i] == province_state[i-1]:\n",
    "        # Check if the current row's 'Deaths' value is equal to 0\n",
    "        if deaths[i] == 0:\n",
    "            # Set the current row's 'Deaths Extended' value to the previous row's value\n",
    "            deaths_extended[i] = deaths_extended[i-1]\n",
    "        else:\n",
    "            # Set the current row's 'Deaths Extended' value to the maximum value between the current and previous rows' 'Deaths' values\n",
    "            deaths_extended[i] = np.maximum(deaths[i], deaths[i-1])\n",
    "\n",
    "# Assign the calculated values to the 'Deaths Extended' column in the DataFrame\n",
    "df2['Deaths Extended'] = deaths_extended\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Pre-allocate memory for an array to store the calculated values\n",
    "deaths_per_day = np.zeros(len(df2))\n",
    "\n",
    "# Use efficient data access methods to access the values in the DataFrame\n",
    "country_region = df2['Country/Region'].values\n",
    "province_state = df2['Province/State'].values\n",
    "deaths_extended = df2['Deaths Extended'].values\n",
    "\n",
    "# Iterate through the rows (starting from the second row) and calculate the values for \"Deaths per day\"\n",
    "for i in range(1, len(df2)):\n",
    "    current_country = country_region[i]\n",
    "    current_province = province_state[i]\n",
    "    prev_country = country_region[i - 1]\n",
    "    prev_province = province_state[i - 1]\n",
    "\n",
    "    if current_country == prev_country and (current_province == prev_province or (pd.isna(current_province) and pd.isna(prev_province))):\n",
    "        deaths_per_day[i] = deaths_extended[i] - deaths_extended[i - 1]\n",
    "    else:\n",
    "        deaths_per_day[i] = deaths_extended[i]\n",
    "\n",
    "# Assign the calculated values to the 'Deaths per day' column in the DataFrame\n",
    "df2['Deaths per day'] = deaths_per_day\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Reassigning the DataFrame with the desired order of columns\n",
    "df2 = df2[['Date', 'Country/Region', 'Province/State', 'Confirmed', 'Confirmed Extended', 'Confirmed per day', 'Recovered', 'Recovered Extended', 'Recovered per day', 'Deaths', 'Deaths Extended', 'Deaths per day']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07a7f0-a67f-4de6-81b1-f7fc6f09a704",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b4590-dae5-4e71-a8f5-3d3815bdc2f1",
   "metadata": {},
   "source": [
    "### Confirming Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7456bccf-3b57-4118-9906-f8510a42e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Confirmed per day                  : 504155460.0\n",
      "Max(Sum(Confirmed Extended)) per Country  : 504155460.0\n",
      "\n",
      "Sum of Recovered per day                  : 135841206.0\n",
      "Max(Sum(Recovered Extended)) per Country  : 135841206.0\n",
      "\n",
      "Sum of Deaths per day                     : 6197163.0\n",
      "Max(Sum(Deaths Extended)) per Country     : 6197163.0\n"
     ]
    }
   ],
   "source": [
    "# Converting Date fields for accurate calculations\n",
    "\n",
    "# Convert the \"Date\" column to pandas datetime using the specified format\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], format='%Y-%m-%d')\n",
    "# Specify the target date in datetime format\n",
    "target_date = pd.to_datetime('16-04-2022', format='%d-%m-%Y')  # \"Y\" stands for 4 digits in Years where as \"y\" stands for 2 digits\n",
    "# Filter the DataFrame to include only rows with the target date\n",
    "target_rows = df2[df2['Date'] == target_date]\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Calculate the sum of \"Confirmed Extended\", \"Recovered Extended\", and \"Deaths Extended\" for the filtered rows\n",
    "sum_cnfrm_ext_on_target_date = target_rows['Confirmed Extended'].sum()\n",
    "sum_rec_ext_on_target_date = target_rows['Recovered Extended'].sum()\n",
    "sum_deaths_ext_on_target_date = target_rows['Deaths Extended'].sum()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Get the sum of the values in the \"Confirmed per day\", \"Recovered per day\", and \"Deaths per day\" columns\n",
    "sum_confirmed_per_day = df2['Confirmed per day'].sum()\n",
    "sum_recovered_per_day = df2['Recovered per day'].sum()\n",
    "sum_deaths_per_day = df2['Deaths per day'].sum()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Printing the relevant values\n",
    "print(\"Sum of Confirmed per day                  :\", sum_confirmed_per_day)\n",
    "print(f\"Max(Sum(Confirmed Extended)) per Country  : {sum_cnfrm_ext_on_target_date}\\n\")\n",
    "print(\"Sum of Recovered per day                  :\", sum_recovered_per_day)\n",
    "print(f\"Max(Sum(Recovered Extended)) per Country  : {sum_rec_ext_on_target_date}\\n\")\n",
    "print(\"Sum of Deaths per day                     :\", sum_deaths_per_day)\n",
    "print(f\"Max(Sum(Deaths Extended)) per Country     : {sum_deaths_ext_on_target_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49068c81-cb96-46ad-8909-ecfd621e6652",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da612ff-bf28-4bc0-8386-e4fb6afbdcb8",
   "metadata": {},
   "source": [
    "### Data Cleaning Post Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b631c6-af30-4ee3-9901-30fb88cc50fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date                  datetime64[ns]\n",
      "Country/Region                object\n",
      "Province/State                object\n",
      "Confirmed                      int64\n",
      "Confirmed Extended           float64\n",
      "Confirmed per day            float64\n",
      "Recovered                    float64\n",
      "Recovered Extended           float64\n",
      "Recovered per day            float64\n",
      "Deaths                         int64\n",
      "Deaths Extended              float64\n",
      "Deaths per day               float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df2.dtypes,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d6e67a-66c4-40d6-bf97-19f8f4767ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the \"datetime64\" datatype from \"Date\" column\n",
    "df2['Date'] = df2['Date'].dt.date\n",
    "\n",
    "# Converting all the \"float64\" datatypes to \"int64\"\n",
    "cols = ['Confirmed Extended', 'Confirmed per day', 'Recovered', 'Recovered Extended', 'Recovered per day', 'Deaths Extended', 'Deaths per day']\n",
    "df2[cols] = df2[cols].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "870fe1a0-9424-45b5-bbd7-698d81ee109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes of the columns are as follows:\n",
      "\n",
      " Date                  object\n",
      "Country/Region        object\n",
      "Province/State        object\n",
      "Confirmed              int64\n",
      "Confirmed Extended     int64\n",
      "Confirmed per day      int64\n",
      "Recovered              int64\n",
      "Recovered Extended     int64\n",
      "Recovered per day      int64\n",
      "Deaths                 int64\n",
      "Deaths Extended        int64\n",
      "Deaths per day         int64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatypes of the columns\n",
    "print(\"The datatypes of the columns are as follows:\\n\\n\",df2.dtypes,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a3513-2a34-4cd8-a06a-42622dd3022e",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd8d07-3a58-4227-a37a-be54589c9a33",
   "metadata": {},
   "source": [
    "### Converting df2 into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0da4bcc4-f987-4036-8dc5-dd4f0ce0b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired file name along with the file extension in the file path\n",
    "file_name = '2a. countries_and_states_transformed.csv'  # Replace 'your_file_name' with your desired name\n",
    "\n",
    "# Convert the DataFrame to an Excel file\n",
    "df2.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202902f5-2d5e-40d7-9254-26fa4bca8dc7",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690e334-c750-4c57-9ab1-b8517d00511a",
   "metadata": {},
   "source": [
    "## 3rd CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfdd008c-a75f-41b6-b81d-1b15dfd44a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Increase rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>500880363</td>\n",
       "      <td>0</td>\n",
       "      <td>6185040</td>\n",
       "      <td>0.207437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>501920234</td>\n",
       "      <td>0</td>\n",
       "      <td>6189593</td>\n",
       "      <td>0.207609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>502892186</td>\n",
       "      <td>0</td>\n",
       "      <td>6193401</td>\n",
       "      <td>0.193647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>2022-04-15</td>\n",
       "      <td>503606396</td>\n",
       "      <td>0</td>\n",
       "      <td>6195647</td>\n",
       "      <td>0.142021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>504155459</td>\n",
       "      <td>0</td>\n",
       "      <td>6197159</td>\n",
       "      <td>0.109026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Confirmed  Recovered   Deaths  Increase rate\n",
       "811  2022-04-12  500880363          0  6185040       0.207437\n",
       "812  2022-04-13  501920234          0  6189593       0.207609\n",
       "813  2022-04-14  502892186          0  6193401       0.193647\n",
       "814  2022-04-15  503606396          0  6195647       0.142021\n",
       "815  2022-04-16  504155459          0  6197159       0.109026"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = '3. worldwide-aggregate.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df4 = pd.read_csv(file_path)\n",
    "\n",
    "# Now you have the data in a DataFrame, and you can perform various operations on it\n",
    "df4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab943d34-8380-4d02-8782-a81122d1c9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Confirmed per day</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Recovered Extended</th>\n",
       "      <th>Recovered per day</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Deaths per day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Country  Confirmed  Confirmed per day  Recovered  \\\n",
       "0  2020-01-22  Afghanistan          0                  0          0   \n",
       "1  2020-01-23  Afghanistan          0                  0          0   \n",
       "2  2020-01-24  Afghanistan          0                  0          0   \n",
       "3  2020-01-25  Afghanistan          0                  0          0   \n",
       "4  2020-01-26  Afghanistan          0                  0          0   \n",
       "\n",
       "   Recovered Extended  Recovered per day  Deaths  Deaths per day  \n",
       "0                   0                  0       0               0  \n",
       "1                   0                  0       0               0  \n",
       "2                   0                  0       0               0  \n",
       "3                   0                  0       0               0  \n",
       "4                   0                  0       0               0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = '1a. countries_transformed.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df3 = pd.read_csv(file_path)\n",
    "\n",
    "# Now you have the data in a DataFrame, and you can perform various operations on it\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b62bd-8d2f-4160-be35-4c657b4c6450",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc6a94-18c3-4179-813b-92a88f072b87",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108f976-f221-4bc4-9d2c-1b397ae5f7e4",
   "metadata": {},
   "source": [
    "![Worldwide Data](https://i.imgur.com/B5mNiEz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb084e1-0506-43fd-8c8f-0ea059fa64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Recovered Extended with respect to each date\n",
    "\n",
    "# Using groupby to achieve objective. Naming the variable 'x' for simplicity.\n",
    "x = df3.groupby('Date')['Recovered Extended'].sum()\n",
    "\n",
    "# Converting from Series to DataFrame\n",
    "rec_ext = x.to_frame().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf9c890d-c4fc-4928-9e9b-184efe0d0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the 'rec_ext' column into df4\n",
    "df4['Recovered Extended'] = rec_ext\n",
    "\n",
    "# Rearranging the columns\n",
    "df4= df4[['Date', 'Confirmed', 'Recovered', 'Recovered Extended', 'Deaths']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588d842-132f-4792-acb7-bfa03a3bab1b",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bcd89-0a8f-4b82-82aa-83d592953ae7",
   "metadata": {},
   "source": [
    "### Converting df4 into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b44e14f-23ac-4feb-a988-ab45aecc10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired file name along with the file extension in the file path\n",
    "file_name = '3a. worldwide_aggregate_transformed.csv'  # Replace 'your_file_name' with your desired name\n",
    "\n",
    "# Convert the DataFrame to an Excel file\n",
    "df4.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21286bd7-336d-4a14-a8c4-91bc36812c1f",
   "metadata": {},
   "source": [
    "-------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
